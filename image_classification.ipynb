{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4V00ayWJ_7n"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pprint"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE-c9UvQKJFr"
      },
      "source": [
        "import joblib\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        " \n",
        "def resize_all(src, pklname, include, width=150, height=None):\n",
        "    \"\"\"\n",
        "    load images from path, resize them and write them as arrays to a dictionary, \n",
        "    together with labels and metadata. The dictionary is written to a pickle file \n",
        "    named '{pklname}_{width}x{height}px.pkl'.\n",
        "     \n",
        "    Parameter\n",
        "    ---------\n",
        "    src: str\n",
        "        path to data\n",
        "    pklname: str\n",
        "        path to output file\n",
        "    width: int\n",
        "        target width of the image in pixels\n",
        "    include: set[str]\n",
        "        set containing str\n",
        "    \"\"\"\n",
        "     \n",
        "    height = height if height is not None else width\n",
        "     \n",
        "    data = dict()\n",
        "    data['description'] = 'resized ({0}x{1})animal images in rgb'.format(int(width), int(height))\n",
        "    data['label'] = []\n",
        "    data['filename'] = []\n",
        "    data['data'] = []   \n",
        "     \n",
        "    pklname = f\"{pklname}_{width}x{height}px.pkl\"\n",
        " \n",
        "    # read all images in PATH, resize and write to DESTINATION_PATH\n",
        "    for subdir in os.listdir(src):\n",
        "        if subdir in include:\n",
        "            print(subdir)\n",
        "            current_path = os.path.join(src, subdir)\n",
        " \n",
        "            for file in os.listdir(current_path):\n",
        "                if file[-3:] in {'jpg', 'png'}:\n",
        "                    im = imread(os.path.join(current_path, file))\n",
        "                    im = resize(im, (width, height)) #[:,:,::-1]\n",
        "                    data['label'].append(subdir[:-4])\n",
        "                    data['filename'].append(file)\n",
        "                    data['data'].append(im)\n",
        " \n",
        "        joblib.dump(data, pklname)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32RasvoJKQ1O"
      },
      "source": [
        "data_path = fr'{os.getenv(\"HOME\")}/downloads/animalface/Image'\n",
        "os.listdir(data_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur8URnR9KcKs"
      },
      "source": [
        "base_name = 'animal_faces'\n",
        "width = 80\n",
        " \n",
        "include = {'ChickenHead', 'BearHead', 'ElephantHead', \n",
        "           'EagleHead', 'DeerHead', 'MonkeyHead', 'PandaHead'}\n",
        " \n",
        "resize_all(src=data_path, pklname=base_name, width=width, include=include)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8WYNXwVKi-m"
      },
      "source": [
        "from collections import Counter\n",
        " \n",
        "data = joblib.load(f'{base_name}_{width}x{width}px.pkl')\n",
        " \n",
        "print('number of samples: ', len(data['data']))\n",
        "print('keys: ', list(data.keys()))\n",
        "print('description: ', data['description'])\n",
        "print('image shape: ', data['data'][0].shape)\n",
        "print('labels:', np.unique(data['label']))\n",
        " \n",
        "Counter(data['label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8wGXwHeKrYp"
      },
      "source": [
        "number of samples:  716\n",
        "keys:  ['description', 'label', 'filename', 'data'] \n",
        "description:  resized (80x80)animal images in rgb \n",
        "image shape:  (80, 80, 3) \n",
        "labels: ['Bear' 'Chicken' 'Deer' 'Eagle' 'Elephant' 'Monkey' 'Panda']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u12XmHjLKw8J"
      },
      "source": [
        "# use np.unique to get all unique values in the list of labels\n",
        "labels = np.unique(data['label'])\n",
        " \n",
        "# set up the matplotlib figure and axes, based on the number of labels\n",
        "fig, axes = plt.subplots(1, len(labels))\n",
        "fig.set_size_inches(15,4)\n",
        "fig.tight_layout()\n",
        " \n",
        "# make a plot for every label (equipment) type. The index method returns the \n",
        "# index of the first item corresponding to its search string, label in this case\n",
        "for ax, label in zip(axes, labels):\n",
        "    idx = data['label'].index(label)\n",
        "     \n",
        "    ax.imshow(data['data'][idx])\n",
        "    ax.axis('off')\n",
        "    ax.set_title(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XohMG4SK6J5"
      },
      "source": [
        "X = np.array(data['data'])\n",
        "y = np.array(data['label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJqV_z5eK_n-"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        " \n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, \n",
        "    y, \n",
        "    test_size=0.2, \n",
        "    shuffle=True,\n",
        "    random_state=42,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFWLqUopL6IY"
      },
      "source": [
        "def plot_bar(y, loc='left', relative=True):\n",
        "    width = 0.35\n",
        "    if loc == 'left':\n",
        "        n = -0.5\n",
        "    elif loc == 'right':\n",
        "        n = 0.5\n",
        "     \n",
        "    # calculate counts per type and sort, to ensure their order\n",
        "    unique, counts = np.unique(y, return_counts=True)\n",
        "    sorted_index = np.argsort(unique)\n",
        "    unique = unique[sorted_index]\n",
        "     \n",
        "    if relative:\n",
        "        # plot as a percentage\n",
        "        counts = 100*counts[sorted_index]/len(y)\n",
        "        ylabel_text = '% count'\n",
        "    else:\n",
        "        # plot counts\n",
        "        counts = counts[sorted_index]\n",
        "        ylabel_text = 'count'\n",
        "         \n",
        "    xtemp = np.arange(len(unique))\n",
        "     \n",
        "    plt.bar(xtemp + n*width, counts, align='center', alpha=.7, width=width)\n",
        "    plt.xticks(xtemp, unique, rotation=45)\n",
        "    plt.xlabel('equipment type')\n",
        "    plt.ylabel(ylabel_text)\n",
        " \n",
        "plt.suptitle('relative amount of photos per type')\n",
        "plot_bar(y_train, loc='left')\n",
        "plot_bar(y_test, loc='right')\n",
        "plt.legend([\n",
        "    'train ({0} photos)'.format(len(y_train)), \n",
        "    'test ({0} photos)'.format(len(y_test))\n",
        "]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqMo1ea3L_NA"
      },
      "source": [
        "from skimage.feature import hog\n",
        "from skimage.io import imread\n",
        "from skimage.transform import rescale\n",
        " \n",
        "dog = imread('Kim_at_14_weeks.jpg', as_gray=True)\n",
        "# https://en.wikipedia.org/wiki/German_Shepherd#/media/File:Kim_at_14_weeks.jpg\n",
        " \n",
        "# scale down the image to one third\n",
        "dog = rescale(dog, 1/3, mode='reflect')\n",
        "# calculate the hog and return a visual representation.\n",
        "dog_hog, dog_hog_img = hog(\n",
        "    dog, pixels_per_cell=(14,14), \n",
        "    cells_per_block=(2, 2), \n",
        "    orientations=9, \n",
        "    visualize=True, \n",
        "    block_norm='L2-Hys')\n",
        " \n",
        "fig, ax = plt.subplots(1,2)\n",
        "fig.set_size_inches(8,6)\n",
        "# remove ticks and their labels\n",
        "[a.tick_params(bottom=False, left=False, labelbottom=False, labelleft=False) \n",
        "    for a in ax]\n",
        " \n",
        "ax[0].imshow(dog, cmap='gray')\n",
        "ax[0].set_title('dog')\n",
        "ax[1].imshow(dog_hog_img, cmap='gray')\n",
        "ax[1].set_title('hog')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0mhxw57MF5U"
      },
      "source": [
        "print('number of pixels: ', dog.shape[0] * dog.shape[1])\n",
        "print('number of hog features: ', dog_hog.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuFKPaiiMMj-"
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        " \n",
        "class RGB2GrayTransformer(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Convert an array of RGB images to grayscale\n",
        "    \"\"\"\n",
        " \n",
        "    def __init__(self):\n",
        "        pass\n",
        " \n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"returns itself\"\"\"\n",
        "        return self\n",
        " \n",
        "    def transform(self, X, y=None):\n",
        "        \"\"\"perform the transformation and return an array\"\"\"\n",
        "        return np.array([skimage.color.rgb2gray(img) for img in X])\n",
        "     \n",
        " \n",
        "class HogTransformer(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Expects an array of 2d arrays (1 channel images)\n",
        "    Calculates hog features for each img\n",
        "    \"\"\"\n",
        " \n",
        "    def __init__(self, y=None, orientations=9,\n",
        "                 pixels_per_cell=(8, 8),\n",
        "                 cells_per_block=(3, 3), block_norm='L2-Hys'):\n",
        "        self.y = y\n",
        "        self.orientations = orientations\n",
        "        self.pixels_per_cell = pixels_per_cell\n",
        "        self.cells_per_block = cells_per_block\n",
        "        self.block_norm = block_norm\n",
        " \n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        " \n",
        "    def transform(self, X, y=None):\n",
        " \n",
        "        def local_hog(X):\n",
        "            return hog(X,\n",
        "                       orientations=self.orientations,\n",
        "                       pixels_per_cell=self.pixels_per_cell,\n",
        "                       cells_per_block=self.cells_per_block,\n",
        "                       block_norm=self.block_norm)\n",
        " \n",
        "        try: # parallel\n",
        "            return np.array([local_hog(img) for img in X])\n",
        "        except:\n",
        "            return np.array([local_hog(img) for img in X])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLapCQ9jMN6B"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.preprocessing import StandardScaler, Normalizer\n",
        "import skimage\n",
        " \n",
        "# create an instance of each transformer\n",
        "grayify = RGB2GrayTransformer()\n",
        "hogify = HogTransformer(\n",
        "    pixels_per_cell=(14, 14), \n",
        "    cells_per_block=(2,2), \n",
        "    orientations=9, \n",
        "    block_norm='L2-Hys'\n",
        ")\n",
        "scalify = StandardScaler()\n",
        " \n",
        "# call fit_transform on each transform converting X_train step by step\n",
        "X_train_gray = grayify.fit_transform(X_train)\n",
        "X_train_hog = hogify.fit_transform(X_train_gray)\n",
        "X_train_prepared = scalify.fit_transform(X_train_hog)\n",
        " \n",
        "print(X_train_prepared.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPtl3tknMQ52"
      },
      "source": [
        "sgd_clf = SGDClassifier(random_state=42, max_iter=1000, tol=1e-3)\n",
        "sgd_clf.fit(X_train_prepared, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Po77Qj8MVNx"
      },
      "source": [
        "X_test_gray = grayify.transform(X_test)\n",
        "X_test_hog = hogify.transform(X_test_gray)\n",
        "X_test_prepared = scalify.transform(X_test_hog)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJ2hPgCAMZSc"
      },
      "source": [
        "y_pred = sgd_clf.predict(X_test_prepared)\n",
        "print(np.array(y_pred == y_test)[:25])\n",
        "print('')\n",
        "print('Percentage correct: ', 100*np.sum(y_pred == y_test)/len(y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgJ7d1hhMd_g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}